{"./":{"url":"./","title":"本书介绍","keywords":"","body":"kubernetes翻译文档 包含以下内容： k8s架构分析 k8s插件介绍 部署实践教程 注解二次开发 "},"setup/":{"url":"setup/","title":"起步文档","keywords":"","body":"起步文档 本章节会列出几种不同的部署并运行k8s集群的方案。当您部署k8s集群的时，请参考以下几个方面作出选择：维护成本、安全性、控制难易、可用资源以及专业知识。 您将k8s集群部署到本地机器、云厂商、数据中心或者选择一个已经部署好的集群。当然，自定义的方案还有云服务提供商和裸机原生环境等。 学习环境 如果您正在学习k8s，建议使用k8s社区支持的工具，或者使用k8s生态中的工具在本地部署一套集群。 生产环境 当应用到生产环境中的时候，请考虑自己的操作技能掌握，或者托管给第三方提供商。 "},"setup/release.html":{"url":"setup/release.html","title":"发版概要","keywords":"","body":"发版提示与版本概要 v1.20 Release Notes Kubernetes version and version skew support policy "},"tasks/tools.html":{"url":"tasks/tools.html","title":"学习环境","keywords":"","body":"安装工具 "},"setup/production-environment.html":{"url":"setup/production-environment.html","title":"生产环境","keywords":"","body":"生产环境介绍 Container runtimes Installing Kubernetes with deployment tools Turnkey Cloud Solutions Windows in Kubernetes "},"setup/best-practices/":{"url":"setup/best-practices/","title":"最佳实践","keywords":"","body":"最佳实践 Considerations for large clusters Running in multiple zones Validate node setup PKI certificates and requirements "},"setup/best-practices/cluster-large.html":{"url":"setup/best-practices/cluster-large.html","title":"考虑大型集群","keywords":"","body":"考虑大型集群 一个集群是由一系列运行k8s客户端的节点（物理机器或者虚拟机）组成，该集群受到控制平面的管理，k8s1.20版本支持高达5000个节点的集群。更具体地来说，k8s基于以下标准设计： 每个节点不超过100个容器组 集群不超过5000个节点 集群总共不超过150000个容器组 集群总共不抄错300000个容器 您可以通过增加或者移除节点实现集群的伸缩，能否达成该点取决于集群的部署方式。 云服务厂商的资源限制 为了避免遇到云服务提供上限额的问题，当常见多节点的集群时候，需要考虑以下几点： 为云资源请求增长的限额，例如：计算实例，CPU核数，存储卷，固定IP，数据包过滤规则，负载均衡器，子网段数量，日志流； 为增加新节点预留空间，因为一些云服务厂商会限制新建实例的速率。 控制平面组件 对于大型集群来说，你需要一个拥有强大算力和其他资源的控制平面。一般情况下，你需要为每一个故障域运行1个到2个控制平面。需要时，先对实例做垂直缩放，当达到极限后再做水平缩放。每个故障域你需要运行至少一个实例来提供容错机制。k8s节点不会自动将流量引向相同故障区域中的控制平面端点，但是您的云服务提供商可能有他自己的实现。例如，使用托管的负载均衡器，你可以配置负载均衡器发送源自故障域A中的kubelet和pod的流量，到也位于区域A中的控制平面主机。如果单节点的控制平面发生故障，导致区域A离线，则会导致区域A中节点的所有控制平面流量现在都在区域之间发送。在每个域中运行多个控制平面可以减少这种情况产生。 etcd存储 为了提高大型集群的性能，您可以通过将事件信息独立存储到etcd实例中。当创建集群的时候，你可以： 启用并配置额外的etcd实例 配置apiserver使用etcd存储事件信息 插件资源 k8s资源限制特性使得内存泄漏和来自pod或者容器的影响最小的影响到其他组件。这些资源限制可以并且应该作用于插件上，正如它们作用在工作负载上一样。例如，你可以为一个日志组件设置CPU和内存限制： ... containers: - name: fluentd-cloud-logging image: fluent/fluentd-kubernetes-daemonset:v1 resources: limits: cpu: 100m memory: 200Mi 插件的默认限制一般基于实践中中小型集群运行插件的经验数据。当运行大型集群的时候，插件经常会消耗比默认限额多很多的资源。如果一个大型集群部署的时候没有调整这些参数，这些插件会不停的由于达到内存限额而被杀死，同理，这些插件也许会由于CPU时间片的限额而运行在低性能下。 为了避免遇到插件的资源限制问题，当创建一个多节点的集群的时候，您需要考虑以下几点： 一些插件垂直扩展-那些一个故障域只需要单个副本的插件；对于这些插件，请在扩展集群的时候增加资源和限制。 大多数插件水平扩展-那些可以通过运行多个pod提升容量的插件；但是针对一个超大的几集群，你可能也需要同时轻微的增加CPU和内存限制。 VerticalPodAutoscaler 运行在recommender模式下可以为请求与限制提供数额建议。 一些插件需要一个节点运行一个-那些通过DaemonSet部署的插件；例如，一个节点级别的日志聚合器，类似于需要水平扩展的插件，这些插件也需要轻微的增加CPU和内存限制。 其他 VerticalPodAutoscaler是一个自定义资源，你可以部署到集群汇总帮助管理pod的资源请求与限制。 cluster autoscaler通过与一系列的云服务提供者交互，帮助你的集群运行足够数量的节点。 "},"setup/best-practices/multiple-zones.html":{"url":"setup/best-practices/multiple-zones.html","title":"多域环境运行","keywords":"","body":"多域环境运行 本节讲解在k8s中运行多个环境。 背景 经过设计，k8s集群可以应对多个故障域问题的情况，一般来说这些域对应到逻辑组中叫做region。主流的云平台定义了地域为一系列故障域的集合，并提供一系列的特色服务：同一地域中，每个故障域提供相同的接口和服务。 控制平面行为 所有的控制平面组件都支持作为可互换资源池运行，每个组件都可被复制。部署集群控制平面时，请将控制平面组件的副本放置在多个故障区域中。如果可用性是一个重要问题，请选择至少三个故障区域，并在至少三个故障区域中复制每个单独的控制平面组件（API服务器，调度程序等，群集控制器管理器）。如果您使用了云厂商提供的控制器，您也应当保证故障域有多个副本。 注意 Kubernetes不为API服务器端点提供跨区域弹性。 您可以使用各种技术来提高群集API服务器的可用性，包括DNS轮询，SRV记录或具有运行状况检查的第三方负载平衡解决方案。 节点行为 节点启动时，每个节点上的kubelet会自动的将标签添加到代表kubernetes api中该特定的kubelet的Node对象。这些标签信息可以包含域信息。如果你的集群跨多个域分布，建议将节点标签搭配pod扩展约束一起使用，以控制pod如何在整个故障域之间分布。这样操作可以使得调度器将pod调度到一个理想的可用性状态，减少相关的出错影响整个工作负载带来的风险。例如，条件允许时，你可以设置限制，将3个副本的StatefulSet应用部署到不同的域中。你可以生命性的定义它，而无需显示定义每个工作负载正在使用哪些域。 节点的跨域分布 k8s本身并不会为您创建节点，你需要自己来执行此操作，或者使用注入Cluster API之类的工具来管理你的节点。使用Cluster API之类的工具可以定义一系列机器集合，这些机器集合作为工作节点分布运行在多个故障域中，也会根据规则自愈集群。 管理域为pod的划分 您可以为你创建的pod设置节点标签限制器，同理，在工作负载类的资源的pod模板中也可以这样操作，例如Deployment,StatefulSet,Job。 存储的跨域 当持久化卷创建时，管理控制器会自动的为关联到域中的持久化卷增加PersistentVolumeLabel标签。调度器随后会做确认，通过NoVolumeZoneConflict来确认pod可以声明一个同域中的持久化卷。你可以为持久化卷声明指定一个存储控制器，该类指定该类中的存储可以使用的故障域。 网络 k8s本身并不支持无感网络，您可以使用网络插件来配置集群网络，并且该网络解决方案可能具有特定于区域的元素。例如，如果您的云服务提供商支持type=LoadBalancer的代理，则负载均衡器可能仅将流量发送到与处理同一连接的负载均衡器的同一个区域中的pod。关于这点，请查阅云厂商的文档。对于自定义或者本地部署的情况，也有类似的注意事项。Service和Ingress的行为，包括如何处理不同的故障与，很大程度上取决于您的集群的部署方式。 错误恢复 当部署集群的时候，你也许需要考虑下是否以及如何让你的集群可以在多个故障域同时离线的情况下恢复，例如，你依赖于每个故障域至少有一个运行pod的节点吗？要知道，任何集群成对的工作不会依赖于集群中至少一个健康节点。例如，如果所有节点都处于不健康状态，你也许需要运行一个修复任务，这个任务会需要一个特殊的容忍度，才能够实现修复至少一个节点的服务。针对这个问题，k8s并没有给出解答，但是这仍然是需要考量的。 "},"setup/best-practices/node-conformance.html":{"url":"setup/best-practices/node-conformance.html","title":"校验节点部署","keywords":"","body":"校验节点部署 节点一致性测试 节点一致性测试是一个容器化的测试框架，可为节点提供系统验证和功能测试。 该测试将验证该节点是否满足Kubernetes的最低要求； 通过测试的节点有资格加入Kubernetes集群。 节点先觉条件 要想运行节点一致性测试，节点必须满足于标准化k8s节点相同的先决条件。至少，该节点需要运行以下守护程序： Container Runtime Kubelet 运行节点一致性测试 运行节点一致性测试，请按照以下步骤操作： 确认kubelet的--kubeconfig值；比如，指定--kubeconfig=/var/lib/kubelet/config.yaml。原因在于测试框架使用本地控制平面来测试kubelet，使用http://localhost:8080作为APIServer的地址。其他可能用到的kubelet命令行参数如下： --pod-cidr: 如果使用了kubenet，需要为kubelet指定一个随机的CIDR，例如：--pod-cidr=10.180.0.0/24。 --cloud-provider：如果使用了参数--cloud-provider=gce，运行前需要移除该参数。 运行以下命令进行测试： # $CONFIG_DIR is the pod manifest path of your Kubelet. # $LOG_DIR is the test output path. sudo docker run -it --rm --privileged --net=host \\ -v /:/rootfs -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \\ k8s.gcr.io/node-test:0.2 其他架构下的一致性测试 k8s为其他架构提供了一致性测试docker镜像： arch image amd64 node-test-amd64 arm node-test-arm arm64 node-test-arm64 运行部分测试 要运行特定的测试，请用要运行的测试的正则表达式覆盖环境变量FOCUS: sudo docker run -it --rm --privileged --net=host \\ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \\ -e FOCUS=MirrorPod \\ # Only run MirrorPod test k8s.gcr.io/node-test:0.2 要跳过特定的测试，请用要跳过的测试的正则表达式覆盖环境变量SKIP: sudo docker run -it --rm --privileged --net=host \\ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \\ -e SKIP=MirrorPod \\ # Run all conformance tests but skip MirrorPod test k8s.gcr.io/node-test:0.2 节点一致性测试是节点e2e测试的容器化版本。默认情况下，它将运行所有一致性测试。从理论上讲，如果您配置了容器并正确安装了所需的卷，则可以运行任何节点e2e测试。 但强烈建议仅运行一致性测试，因为它需要更复杂的配置才能运行不一致性测试。 注意事项 该项测试会在节点上留下docker镜像，包含一致性测试镜像和功能测试的容器 测试会在节点上留下停止运行的容器，这些容器在功能测试的过程中创建。 "},"setup/best-practices/certificates.html":{"url":"setup/best-practices/certificates.html","title":"PKI证书问题","keywords":"","body":"PKI证书问题 k8s需要基于TLS的PKI证书授权。如果您使用了kubeadm部署的k8s，集群会自动生成需要的证书。当然，你也可以自己手动创建证书。例如，为了保证私有证书更加安全，你可以将其不存放在API Server中。本文讲解集群需要的证书。 集群是如何使用证书的 k8s在以下操作的时候需要用到PKI认证： kubelet访问API Server需要客户端证书 APIserver 端点需要服务端证书 集群管理员认证API server需要客户端证书 API server与kubelet通信需要客户端证书 API server与etcd通信需要客户端证书 controller manager与API server通信时候需要客户端证书和kubeconfig scheduler与API server通信时候需要客户端证书和kubeconfig 前置代理需要客户端和服务端证书 注意 前置代理需要证书的场景仅存在于运行kube-proxy支撑APIserver扩展的时候。 etcd在授权客户端和节点的时候也实现了一般的TLS认证 证书的存放位置 使用kubeadm安装k8s的时候，证书存放在/etc/kubernetes/pki，本文中提到的所有路径都是相对于该目录。 手动配置证书 如果你不想kubeadm自动生成证书的话，你可以使用以下几种方式创建： 单独根CA证书 你可以使用管理员创建一个根证书。然后，该根CA可以创建多个中间CA，并将所有进一步的创建委托给Kubernetes本身。 需要的CA： 路径 默认cn 描述 ca.crt,key kubernetes-ca Kubernetes general CA etcd/ca.crt,key etcd-ca For all etcd-related functions front-proxy-ca.crt,key kubernetes-front-proxy-ca For the front-end proxy 在上述CA之上，还需要获取用于服务帐户管理的公共/私有密钥对sa.key和sa.pub。 所有证书 如果你不想复制这些证书到你的集群中，你可以自己生成这些证书。 需要的证书如下： 默认CN 父证书 O 类型 hosts kube-etcd etcd-ca server, client localhost, 127.0.0.1 kube-etcd-peer etcd-ca server, client hostname, Host_IP, localhost, 127.0.0.1 kube-etcd-healthcheck-client etcd-ca client kube-apiserver-etcd-client etcd-ca system:masters client kube-apiserver kubernetes-ca server hostname, Host_IP, advertise_IP, [1] kube-apiserver-kubelet-client kubernetes-ca system:masters client front-proxy-client kubernetes-front-proxy-ca client [1]： 表示访问集群的其他任何IP或者DNS名称，其中kind映射到一种或多种x509密钥用法类型： kind 密钥用法 server digital signature, key encipherment, server auth client digital signature, key encipherment, client auth 注意：上面列出的主机/SAN是获得工作群集的推荐主机； 如果特定设置需要，则可以在所有服务器证书上添加其他SAN。 注意：对于kubeadm用户而言只需要如下： 在不使用私钥的情况下复制到群集CA证书的方案在kubeadm文档中称为外部CA。 如果将上面的列表与kubeadm生成的PKI进行比较，请注意，如果使用外部etcd，则不会生成kube-etcd，kube-etcd-peer和kube-etcd-healthcheck-client证书。 证书路径 证书应当存放在推荐的路径下，路径需要通过特定的参数指定而不是路径。 Default CN recommended key path recommended cert path command key argument cert argument etcd-ca etcd/ca.key etcd/ca.crt kube-apiserver --etcd-cafile kube-apiserver-etcd-client apiserver-etcd-client.key apiserver-etcd-client.crt kube-apiserver --etcd-keyfile --etcd-certfile kubernetes-ca ca.key ca.crt kube-apiserver --client-ca-file kubernetes-ca ca.key ca.crt kube-controller-manager --cluster-signing-key-file --client-ca-file, --root-ca-file, --cluster-signing-cert-file kube-apiserver apiserver.key apiserver.crt kube-apiserver --tls-private-key-file --tls-cert-file kube-apiserver-kubelet-client apiserver-kubelet-client.key apiserver-kubelet-client.crt kube-apiserver --kubelet-client-key --kubelet-client-certificate front-proxy-ca front-proxy-ca.key front-proxy-ca.crt kube-apiserver --requestheader-client-ca-file front-proxy-ca front-proxy-ca.key front-proxy-ca.crt kube-controller-manager --requestheader-client-ca-file front-proxy-client front-proxy-client.key front-proxy-client.crt kube-apiserver --proxy-client-key-file --proxy-client-cert-file etcd-ca etcd/ca.key etcd/ca.crt etcd --trusted-ca-file, --peer-trusted-ca-file kube-etcd etcd/server.key etcd/server.crt etcd --key-file --cert-file kube-etcd-peer etcd/peer.key etcd/peer.crt etcd --peer-key-file --peer-cert-file etcd-ca etcd/ca.crt etcdctl --cacert kube-etcd-healthcheck-client etcd/healthcheck-client.key etcd/healthcheck-client.crt etcdctl --key --cert 相同的注意事项适用于服务帐户密钥对： private key path public key path command argument sa.key kube-controller-manager --service-account-private-key-file sa.pub kube-apiserver --service-account-key-file 用户账户的证书配置 你必须要配置这些管理员账户和服务账户： filename credential name Default CN O (in Subject) admin.conf default-admin kubernetes-admin system:masters kubelet.conf default-auth system:node: (see note) system:nodes controller-manager.conf default-controller-manager system:kube-controller-manager scheduler.conf default-scheduler system:kube-scheduler 注意：kubelet.conf的的值必须与kubelet向apiserver注册时提供的节点名称的值完全匹配。 有关更多详细信息，请阅读节点授权。 对于每个配置，请使用给定的CN和O生成一个x509证书/密钥对。 对每个配置运行kubectl，如下所示： KUBECONFIG= kubectl config set-cluster default-cluster --server=https://:6443 --certificate-authority --embed-certs KUBECONFIG= kubectl config set-credentials --client-key .pem --client-certificate .pem --embed-certs KUBECONFIG= kubectl config set-context default-system --cluster default-cluster --user KUBECONFIG= kubectl config use-context default-system 这些文件的用途如下： filename command comment admin.conf kubectl Configures administrator user for the cluster kubelet.conf kubelet One required for each node in the cluster. controller-manager.conf kube-controller-manager Must be added to manifest in manifests/kube-controller-manager.yaml scheduler.conf kube-scheduler Must be added to manifest in manifests/kube-scheduler.yaml "},"concepts/":{"url":"concepts/","title":"内容详解","keywords":"","body":"内容详解 本章节帮助你了解Kubernetes系统的各个部分以及Kubernetes用于表示集群的抽象，并有助于您更深入地了解Kubernetes的工作原理。 "},"concepts/overview/":{"url":"concepts/overview/","title":"集群概览","keywords":"","body":"集群概览 什么时k8s k8s是一个便携的，可扩展的，以及开源的平台，用来管理容器化的工作负载和服务，该基础设施兼具声明式配置和自动化特性。k8s是一个大型的，快速成长的生态系统。使用k8s服务，支持以及工具，具备广泛的可行性。 k8s组件 k8s集群由代表控制平面的组件以及机器集合组成的node节点组件组成。 k8s api k8s api允许你查询和管理集群对象的状态。k8s核心的控制平面包含由api server以及http api暴露出来的接口。用户之间，集群中的不同部分，以及外部组件之间的所有通信都是通过api server完成。 理解k8s对象 k8s对象是k8s系统中的持久化内容。k8s使用这些内容代表集群。学习k8s对象模型，以及如何使用这些对象。 "},"concepts/overview/what-is-kubernetes.html":{"url":"concepts/overview/what-is-kubernetes.html","title":"什么是k8s","keywords":"","body":"什么是k8s "},"concepts/overview/components.html":{"url":"concepts/overview/components.html","title":"k8s组件","keywords":"","body":"k8s组件 "},"concepts/overview/kubernetes-api.html":{"url":"concepts/overview/kubernetes-api.html","title":"k8s api","keywords":"","body":"k8s api "},"concepts/overview/working-with-objects/":{"url":"concepts/overview/working-with-objects/","title":"k8s 资源对象","keywords":"","body":"k8s 资源对象 "},"concepts/overview/working-with-objects/kubernetes-objects.html":{"url":"concepts/overview/working-with-objects/kubernetes-objects.html","title":"理解k8s对象","keywords":"","body":"理解k8s对象 "},"concepts/overview/working-with-objects/object-management.html":{"url":"concepts/overview/working-with-objects/object-management.html","title":"对象的管理","keywords":"","body":"对象的管理 "},"overview/working-with-objects/names.html":{"url":"overview/working-with-objects/names.html","title":"对象的名称和ID","keywords":"","body":"对象的名称和ID "},"concepts/overview/working-with-objects/namespaces.html":{"url":"concepts/overview/working-with-objects/namespaces.html","title":"名称空间","keywords":"","body":"名称空间 "},"concepts/overview/working-with-objects/labels.html":{"url":"concepts/overview/working-with-objects/labels.html","title":"标签和标签选择器","keywords":"","body":"标签和标签选择器 "},"concepts/overview/working-with-objects/annotations.html":{"url":"concepts/overview/working-with-objects/annotations.html","title":"注解","keywords":"","body":"注解 "},"concepts/overview/working-with-objects/field-selectors.html":{"url":"concepts/overview/working-with-objects/field-selectors.html","title":"字段选择器","keywords":"","body":"字段选择器 "},"concepts/overview/working-with-objects/common-labels.html":{"url":"concepts/overview/working-with-objects/common-labels.html","title":"推荐的标签","keywords":"","body":"推荐的标签 "},"concepts/architecture/":{"url":"concepts/architecture/","title":"集群架构","keywords":"","body":"集群架构 "},"concepts/architecture/nodes.html":{"url":"concepts/architecture/nodes.html","title":"节点","keywords":"","body":"节点 "},"concepts/architecture/control-plane-node-communication.html":{"url":"concepts/architecture/control-plane-node-communication.html","title":"控制平面与节点通信","keywords":"","body":"控制平面与节点通信 "},"concepts/architecture/controller.html":{"url":"concepts/architecture/controller.html","title":"控制器","keywords":"","body":"控制器 "},"concepts/architecture/cloud-controller.html":{"url":"concepts/architecture/cloud-controller.html","title":"云控制器管理","keywords":"","body":"云控制器管理 "},"concepts/containers/":{"url":"concepts/containers/","title":"容器详解","keywords":"","body":"容器详解 "},"concepts/containers/images.html":{"url":"concepts/containers/images.html","title":"镜像","keywords":"","body":"镜像 "},"concepts/containers/container-environment.html":{"url":"concepts/containers/container-environment.html","title":"容器运行环境","keywords":"","body":"容器运行环境 "},"concepts/containers/runtime-class.html":{"url":"concepts/containers/runtime-class.html","title":"运行时类","keywords":"","body":"运行时类 "},"concepts/containers/container-lifecycle-hooks.html":{"url":"concepts/containers/container-lifecycle-hooks.html","title":"容器声明周期钩子","keywords":"","body":"容器声明周期钩子 "},"concepts/workloads/":{"url":"concepts/workloads/","title":"工作负载","keywords":"","body":"工作负载 "},"concepts/workloads/pods/":{"url":"concepts/workloads/pods/","title":"容器组","keywords":"","body":"容器组 "},"concepts/workloads/pods/pod-lifecycle.html":{"url":"concepts/workloads/pods/pod-lifecycle.html","title":"容器组声明周期","keywords":"","body":"容器组声明周期 "},"concepts/workloads/pods/init-containers.html":{"url":"concepts/workloads/pods/init-containers.html","title":"初始化容器","keywords":"","body":"初始化容器 "},"concepts/workloads/controllers/":{"url":"concepts/workloads/controllers/","title":"负载资源","keywords":"","body":"负载资源 "},"concepts/workloads/controllers/deployment.html":{"url":"concepts/workloads/controllers/deployment.html","title":"部署器","keywords":"","body":"部署器 "},"concepts/workloads/controllers/replicaset.html":{"url":"concepts/workloads/controllers/replicaset.html","title":"副本集","keywords":"","body":"副本集 "},"concepts/services-networking.html":{"url":"concepts/services-networking.html","title":"代理、负载均衡与网络","keywords":"","body":"代理、负载均衡与网络 "},"concepts/storage.html":{"url":"concepts/storage.html","title":"后端存储","keywords":"","body":"后端存储 "},"concepts/configuration.html":{"url":"concepts/configuration.html","title":"配置定义","keywords":"","body":"配置定义 "},"concepts/security.html":{"url":"concepts/security.html","title":"安全策略","keywords":"","body":"安全策略 "},"concepts/policy.html":{"url":"concepts/policy.html","title":"资源策略","keywords":"","body":"资源策略 "},"concepts/scheduling-eviction.html":{"url":"concepts/scheduling-eviction.html","title":"调度驱逐","keywords":"","body":"调度驱逐 "},"concepts/cluster-administration.html":{"url":"concepts/cluster-administration.html","title":"集群管理","keywords":"","body":"集群管理 "},"concepts/extend-kubernetes.html":{"url":"concepts/extend-kubernetes.html","title":"功能扩展","keywords":"","body":"功能扩展 "},"tasks/":{"url":"tasks/","title":"新手教程","keywords":"","body":"新手教程 "},"tasks/administer-cluste.html":{"url":"tasks/administer-cluste.html","title":"管理集群","keywords":"","body":"管理集群 "},"tasks/configure-pod-container.html":{"url":"tasks/configure-pod-container.html","title":"配置容器","keywords":"","body":"配置容器 "},"tasks/manage-kubernetes-objects.html":{"url":"tasks/manage-kubernetes-objects.html","title":"管理对象","keywords":"","body":"管理对象 "},"tasks/configmap-secret.html":{"url":"tasks/configmap-secret.html","title":"管理密钥","keywords":"","body":"管理密钥 "},"tasks/inject-data-application.html":{"url":"tasks/inject-data-application.html","title":"容器交互","keywords":"","body":"容器交互 "},"tasks/run-application.html":{"url":"tasks/run-application.html","title":"部署服务","keywords":"","body":"部署服务 "},"tasks/job.html":{"url":"tasks/job.html","title":"部署任务","keywords":"","body":"部署任务 "},"tasks/access-application-cluster.html":{"url":"tasks/access-application-cluster.html","title":"访问服务","keywords":"","body":"访问服务 "},"tasks/debug-application-cluster.html":{"url":"tasks/debug-application-cluster.html","title":"监控、审计与调试","keywords":"","body":"监控、审计与调试 "},"tasks/extend-kubernetes.html":{"url":"tasks/extend-kubernetes.html","title":"扩展集群","keywords":"","body":"扩展集群 "},"tasks/tls.html":{"url":"tasks/tls.html","title":"证书加密","keywords":"","body":"证书加密 "},"tasks/manage-daemon.html":{"url":"tasks/manage-daemon.html","title":"守护服务","keywords":"","body":"守护服务 "},"tasks/service-catalog.html":{"url":"tasks/service-catalog.html","title":"服务管理","keywords":"","body":"服务管理 "},"tasks/network.html":{"url":"tasks/network.html","title":"网络实践","keywords":"","body":"网络实践 "},"tasks/kubelet-credential-provider/kubelet-credential-provider.html":{"url":"tasks/kubelet-credential-provider/kubelet-credential-provider.html","title":"配置一个客户端景象认证服务","keywords":"","body":"配置一个客户端景象认证服务 "},"tasks/extend-kubectl/kubectl-plugins.html":{"url":"tasks/extend-kubectl/kubectl-plugins.html","title":"使用插件扩展集群","keywords":"","body":"使用插件扩展集群 "},"tasks/manage-hugepages/scheduling-hugepages.html":{"url":"tasks/manage-hugepages/scheduling-hugepages.html","title":"管理大页码","keywords":"","body":"管理大页码 "},"tasks/manage-gpus/scheduling-gpus.html":{"url":"tasks/manage-gpus/scheduling-gpus.html","title":"调度GPU","keywords":"","body":"调度GPU "}}